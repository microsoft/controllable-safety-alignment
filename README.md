## Controllable Safety Alignment
This is the codebase for our ICLR 2025 paper *Controllable Safety Alignment: Inference-Time Adaptation to Diverse Safety Requirements*.

Please see a summary of our artifacts in our HuggingFace collection: [Controllable Safety Alignment ðŸ¤—](https://huggingface.co/collections/jackzhang/controllable-safety-alignment-677850d9175e7d2615404504).

We will release the full codebase soon. At this moment, we have publicly released the CoSApien dataset and the CoSAlign model which can be accessed here:

- **CoSApienðŸ‘¥ dataset**: [link](https://huggingface.co/datasets/jackzhang/CoSApien)
- **Llama3.1-8B-Instruct-CoSAlign**ðŸ¤–: [link](https://huggingface.co/jackzhang/Llama3.1-8B-Instruct-CoSAlign)

If you have questions feel free to email the authors.

## Reference
If you find our work useful, please consider citing our paper:
```bibtex
@inproceedings{zhang2025controllablesafetyalignment,
      title={Controllable Safety Alignment: Inference-Time Adaptation to Diverse Safety Requirements}, 
      author={Jingyu Zhang and Ahmed Elgohary and Ahmed Magooda and Daniel Khashabi and Benjamin Van Durme},
      year={2025},
      url={https://arxiv.org/abs/2410.08968},
      booktitle = {International Conference on Learning Representations (ICLR)}
}
```
